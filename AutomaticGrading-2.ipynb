{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re \n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = open(\"/Users/savita/Desktop/computeCost3.txt\",\"r\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = open(\"/Users/savita/Desktop/computeCost4.txt\",\"r\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = open(\"/Users/savita/Desktop/gradientDescent.txt\",\"r\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contents1 = text1.read()\n",
    "file_contents2 = text2.read()\n",
    "file_contents3 = text3.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'function J = computeCost(X, y, theta)\\n%COMPUTECOST Compute cost for linear regression\\n%   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the\\n%   parameter for linear regression to fit the data points in X and y\\n\\n% Initialize some useful values\\nm = length(X); % number of training examples\\n% ====================== YOUR CODE HERE ======================\\n% Instructions: Compute the cost of a particular choice of theta\\n%               You should set J to the cost.\\nJ = 0;\\nJ=1/(2*m)*(sum(((X*theta)-y).^2));\\n% =========================================================================\\nend\\n\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_contents1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"function [theta, J_history] = gradientDescent(X, y, theta, alpha, num_iters)\\n%GRADIENTDESCENT Performs gradient descent to learn theta\\n%   theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by \\n%   taking num_iters gradient steps with learning rate alpha\\n\\n% Initialize some useful values\\nm = length(X); % number of training examples\\nJ_history = zeros(num_iters, 1);\\n\\nfor iter = 1:num_iters\\n    % ====================== YOUR CODE HERE ======================\\n    % Instructions: Perform a single gradient step on the parameter vector\\n    %               theta. \\n    %\\n    % Hint: While debugging, it can be useful to print out the values\\n    %       of the cost function (computeCost) and gradient here.\\n    dell=(1/m)*((X*theta-y)' * X)';\\n    theta = theta - (alpha * dell);  \\n    % ============================================================\\n    % Save the cost J in every iteration    \\n    J_history(iter) = computeCost(X, y, theta);\\nend\\n\\nend\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_contents2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/savita/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'function J = computeCost(X, y, theta)\\n%COMPUTECOST Compute cost for linear regression\\n%   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the\\n%   parameter for linear regression to fit the data points in X and y\\n\\n% Initialize some useful values\\na = length(X); % number of training examples\\n% ====================== YOUR CODE HERE ======================\\n% Instructions: Compute the cost of a particular choice of theta\\n%               You should set J to the cost.\\nJ = 0;\\nJ=1/(a)*(sum(((X*theta)-y).^2));\\n% =========================================================================\\nend\\n\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_contents3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text1 = re.sub(r'%(.*)\\n','',file_contents1)\n",
    "clean_text1 = re.sub(r'\\s+',' ',clean_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'function J = computeCost(X, y, theta) m = length(X); J = 0; J=1/(2*m)*(sum(((X*theta)-y).^2)); end '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"function [theta, J_history] = gradientDescent(X, y, theta, alpha, num_iters) m = length(X); J_history = zeros(num_iters, 1); for iter = 1:num_iters dell=(1/m)*((X*theta-y)' * X)'; theta = theta - (alpha * dell); J_history(iter) = computeCost(X, y, theta); end end\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text2 = re.sub(r'%(.*)\\n','',file_contents2)\n",
    "clean_text2 = re.sub(r'\\s+',' ',clean_text2)\n",
    "clean_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'function J = computeCost(X, y, theta) a = length(X); J = 0; J=1/(a)*(sum(((X*theta)-y).^2)); end '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text3 = re.sub(r'%(.*)\\n','',file_contents3)\n",
    "clean_text3 = re.sub(r'\\s+',' ',clean_text3)\n",
    "clean_text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'function J = computeCost(X, y, theta) m = length(X); J = 0; J=1/(2*m)*(sum(((X*theta)-y).^2)); end '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Matcher from difflib python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does string matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=difflib.SequenceMatcher(None,clean_text1,clean_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<difflib.SequenceMatcher at 0x113a5eba8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=seq.ratio()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.93877551020408\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI using ngram method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents =[clean_text1,clean_text2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "text = [[' '.join(nltk.word_tokenize(document)[i:i+n]) for i in range(len(nltk.word_tokenize(document))-n)]\n",
    "         for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['function J', 'J =', '= computeCost', 'computeCost (', '( X', 'X ,', ', y', 'y ,', ', theta', 'theta )', ') m', 'm =', '= length', 'length (', '( X', 'X )', ') ;', '; J', 'J =', '= 0', '0 ;', '; J=1/', 'J=1/ (', '( 2*m', '2*m )', ') *', '* (', '( sum', 'sum (', '( (', '( (', '( X*theta', 'X*theta )', ') -y', '-y )', ') .^2', '.^2 )', ') )', ') ;'], ['function [', '[ theta', 'theta ,', ', J_history', 'J_history ]', '] =', '= gradientDescent', 'gradientDescent (', '( X', 'X ,', ', y', 'y ,', ', theta', 'theta ,', ', alpha', 'alpha ,', ', num_iters', 'num_iters )', ') m', 'm =', '= length', 'length (', '( X', 'X )', ') ;', '; J_history', 'J_history =', '= zeros', 'zeros (', '( num_iters', 'num_iters ,', ', 1', '1 )', ') ;', '; for', 'for iter', 'iter =', '= 1', '1 :', ': num_iters', 'num_iters dell=', 'dell= (', '( 1/m', '1/m )', ') *', '* (', '( (', '( X*theta-y', 'X*theta-y )', \") '\", \"' *\", '* X', 'X )', \") '\", \"' ;\", '; theta', 'theta =', '= theta', 'theta -', '- (', '( alpha', 'alpha *', '* dell', 'dell )', ') ;', '; J_history', 'J_history (', '( iter', 'iter )', ') =', '= computeCost', 'computeCost (', '( X', 'X ,', ', y', 'y ,', ', theta', 'theta )', ') ;', '; end']]\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = [[word for word in nltk.word_tokenize(document)]\n",
    "         for document in documents]\n",
    "\n",
    "#adding the trigram fetures to the corpus to increase the semantic similarity \n",
    "n=2\n",
    "text2 = [[' '.join(nltk.word_tokenize(document)[i:i+n]) for i in range(len(nltk.word_tokenize(document))-n)]\n",
    "         for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text1 + text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['function',\n",
       "  'J',\n",
       "  '=',\n",
       "  'computeCost',\n",
       "  '(',\n",
       "  'X',\n",
       "  ',',\n",
       "  'y',\n",
       "  ',',\n",
       "  'theta',\n",
       "  ')',\n",
       "  'm',\n",
       "  '=',\n",
       "  'length',\n",
       "  '(',\n",
       "  'X',\n",
       "  ')',\n",
       "  ';',\n",
       "  'J',\n",
       "  '=',\n",
       "  '0',\n",
       "  ';',\n",
       "  'J=1/',\n",
       "  '(',\n",
       "  '2*m',\n",
       "  ')',\n",
       "  '*',\n",
       "  '(',\n",
       "  'sum',\n",
       "  '(',\n",
       "  '(',\n",
       "  '(',\n",
       "  'X*theta',\n",
       "  ')',\n",
       "  '-y',\n",
       "  ')',\n",
       "  '.^2',\n",
       "  ')',\n",
       "  ')',\n",
       "  ';',\n",
       "  'end'],\n",
       " ['function',\n",
       "  '[',\n",
       "  'theta',\n",
       "  ',',\n",
       "  'J_history',\n",
       "  ']',\n",
       "  '=',\n",
       "  'gradientDescent',\n",
       "  '(',\n",
       "  'X',\n",
       "  ',',\n",
       "  'y',\n",
       "  ',',\n",
       "  'theta',\n",
       "  ',',\n",
       "  'alpha',\n",
       "  ',',\n",
       "  'num_iters',\n",
       "  ')',\n",
       "  'm',\n",
       "  '=',\n",
       "  'length',\n",
       "  '(',\n",
       "  'X',\n",
       "  ')',\n",
       "  ';',\n",
       "  'J_history',\n",
       "  '=',\n",
       "  'zeros',\n",
       "  '(',\n",
       "  'num_iters',\n",
       "  ',',\n",
       "  '1',\n",
       "  ')',\n",
       "  ';',\n",
       "  'for',\n",
       "  'iter',\n",
       "  '=',\n",
       "  '1',\n",
       "  ':',\n",
       "  'num_iters',\n",
       "  'dell=',\n",
       "  '(',\n",
       "  '1/m',\n",
       "  ')',\n",
       "  '*',\n",
       "  '(',\n",
       "  '(',\n",
       "  'X*theta-y',\n",
       "  ')',\n",
       "  \"'\",\n",
       "  '*',\n",
       "  'X',\n",
       "  ')',\n",
       "  \"'\",\n",
       "  ';',\n",
       "  'theta',\n",
       "  '=',\n",
       "  'theta',\n",
       "  '-',\n",
       "  '(',\n",
       "  'alpha',\n",
       "  '*',\n",
       "  'dell',\n",
       "  ')',\n",
       "  ';',\n",
       "  'J_history',\n",
       "  '(',\n",
       "  'iter',\n",
       "  ')',\n",
       "  '=',\n",
       "  'computeCost',\n",
       "  '(',\n",
       "  'X',\n",
       "  ',',\n",
       "  'y',\n",
       "  ',',\n",
       "  'theta',\n",
       "  ')',\n",
       "  ';',\n",
       "  'end',\n",
       "  'end'],\n",
       " ['function J',\n",
       "  'J =',\n",
       "  '= computeCost',\n",
       "  'computeCost (',\n",
       "  '( X',\n",
       "  'X ,',\n",
       "  ', y',\n",
       "  'y ,',\n",
       "  ', theta',\n",
       "  'theta )',\n",
       "  ') m',\n",
       "  'm =',\n",
       "  '= length',\n",
       "  'length (',\n",
       "  '( X',\n",
       "  'X )',\n",
       "  ') ;',\n",
       "  '; J',\n",
       "  'J =',\n",
       "  '= 0',\n",
       "  '0 ;',\n",
       "  '; J=1/',\n",
       "  'J=1/ (',\n",
       "  '( 2*m',\n",
       "  '2*m )',\n",
       "  ') *',\n",
       "  '* (',\n",
       "  '( sum',\n",
       "  'sum (',\n",
       "  '( (',\n",
       "  '( (',\n",
       "  '( X*theta',\n",
       "  'X*theta )',\n",
       "  ') -y',\n",
       "  '-y )',\n",
       "  ') .^2',\n",
       "  '.^2 )',\n",
       "  ') )',\n",
       "  ') ;'],\n",
       " ['function [',\n",
       "  '[ theta',\n",
       "  'theta ,',\n",
       "  ', J_history',\n",
       "  'J_history ]',\n",
       "  '] =',\n",
       "  '= gradientDescent',\n",
       "  'gradientDescent (',\n",
       "  '( X',\n",
       "  'X ,',\n",
       "  ', y',\n",
       "  'y ,',\n",
       "  ', theta',\n",
       "  'theta ,',\n",
       "  ', alpha',\n",
       "  'alpha ,',\n",
       "  ', num_iters',\n",
       "  'num_iters )',\n",
       "  ') m',\n",
       "  'm =',\n",
       "  '= length',\n",
       "  'length (',\n",
       "  '( X',\n",
       "  'X )',\n",
       "  ') ;',\n",
       "  '; J_history',\n",
       "  'J_history =',\n",
       "  '= zeros',\n",
       "  'zeros (',\n",
       "  '( num_iters',\n",
       "  'num_iters ,',\n",
       "  ', 1',\n",
       "  '1 )',\n",
       "  ') ;',\n",
       "  '; for',\n",
       "  'for iter',\n",
       "  'iter =',\n",
       "  '= 1',\n",
       "  '1 :',\n",
       "  ': num_iters',\n",
       "  'num_iters dell=',\n",
       "  'dell= (',\n",
       "  '( 1/m',\n",
       "  '1/m )',\n",
       "  ') *',\n",
       "  '* (',\n",
       "  '( (',\n",
       "  '( X*theta-y',\n",
       "  'X*theta-y )',\n",
       "  \") '\",\n",
       "  \"' *\",\n",
       "  '* X',\n",
       "  'X )',\n",
       "  \") '\",\n",
       "  \"' ;\",\n",
       "  '; theta',\n",
       "  'theta =',\n",
       "  '= theta',\n",
       "  'theta -',\n",
       "  '- (',\n",
       "  '( alpha',\n",
       "  'alpha *',\n",
       "  '* dell',\n",
       "  'dell )',\n",
       "  ') ;',\n",
       "  '; J_history',\n",
       "  'J_history (',\n",
       "  '( iter',\n",
       "  'iter )',\n",
       "  ') =',\n",
       "  '= computeCost',\n",
       "  'computeCost (',\n",
       "  '( X',\n",
       "  'X ,',\n",
       "  ', y',\n",
       "  'y ,',\n",
       "  ', theta',\n",
       "  'theta )',\n",
       "  ') ;',\n",
       "  '; end']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = clean_text2\n",
    "vec_bow = dictionary.doc2bow(nltk.word_tokenize(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "vec_lsi = lsi[vec_bow]\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.99999994), (0, 0.83837235), (2, 0.0), (3, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[vec_lsi]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winnowing Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#sha-1 encoding is used to generate hash values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash(text):\n",
    "    #this function generates hash values\n",
    "    hashval = hashlib.sha1(text.encode('utf-8'))\n",
    "    hashval = hashval.hexdigest()[-4 :]\n",
    "    hashval = int(hashval, 16)  #using last 16 bits of sha-1 digest\n",
    "    return hashval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that returns the index at which minimum value of a given list (window) is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minIndex(arr):\n",
    "    minI = 0\n",
    "    minV = arr[0]\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        if arr[i] < minV:\n",
    "            minV = arr[i]\n",
    "            minI = i\n",
    "    return minI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form windows of hash values and use min-hash to limit the number of fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fingerprints(arr, winSize = 4):\n",
    "    arrLen = len(arr)\n",
    "    prevMin = 0\n",
    "    currMin = 0\n",
    "    windows = []\n",
    "    fingerprintList = []\n",
    "    for i in range(arrLen - winSize):\n",
    "        win = arr[i: i + winSize]  #forming windows\n",
    "        windows.append(win)\n",
    "        currMin = i + minIndex(win)\n",
    "        if not currMin == prevMin:  #min value of window is stored only if it is not the same as min value of prev window\n",
    "            fingerprintList.append(arr[currMin])  #reduces the number of fingerprints while maintaining guarantee\n",
    "            prevMin = currMin  #refer to density of winnowing and guarantee threshold (Stanford paper)\n",
    "\n",
    "    return fingerprintList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes k-gram list as input and returns a list of only hash values\n",
    "def hashList(arr):\n",
    "    HL = []\n",
    "    for i in arr:\n",
    "        HL.append(i[1])\n",
    "\n",
    "    return HL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plagiarismCheck(file1, file2):\n",
    "    text1 = open(file1, \"r\")\n",
    "    file_contents1 = text1.read()\n",
    "    clean_text1 = re.sub(r'%(.*)\\n','',file_contents1)\n",
    "    clean_text1 = re.sub(r'\\s+',' ',clean_text1)\n",
    "    n=2\n",
    "    text11 = [[' '.join(nltk.word_tokenize(clean_text1)[i:i+n]) for i in range(len(nltk.word_tokenize(clean_text1))-n)]]\n",
    "    text2 = open(file1, \"r\")\n",
    "    file_contents2 = text2.read()\n",
    "    clean_text2 = re.sub(r'%(.*)\\n','',file_contents2)\n",
    "    clean_text2 = re.sub(r'\\s+',' ',clean_text2)  \n",
    "    text22 = [[' '.join(nltk.word_tokenize(clean_text2)[i:i+n]) for i in range(len(nltk.word_tokenize(clean_text2))-n)]]\n",
    "    HL1 = hashList(text11)  #hash list derived from k-grams list\n",
    "    HL2 = hashList(text22)\n",
    "    fpList1 = fingerprints(HL1)\n",
    "    fpList2 = fingerprints(HL2)\n",
    "    start = []   #to store the start values corresponding to matching fingerprints\n",
    "    end = []   #to store end values\n",
    "    code = f1.read()  #original code\n",
    "    newCode = \"\"   #code with marked plagiarized content\n",
    "    points = []\n",
    "    for i in fpList1:\n",
    "        for j in fpList2:\n",
    "            if i == j:   #fingerprints match\n",
    "                flag = 0\n",
    "                match = HL1.index(i)   #index of matching fingerprints in hash list, k-grams list\n",
    "                newStart = kGrams1[match][2]   #start position of matched k-gram in cleaned up code\n",
    "                newEnd = kGrams1[match][3]   #end position\n",
    "                for k in token1:\n",
    "                    if k[2] == newStart:   #linking positions in cleaned up code to original code\n",
    "                        startx = k[1]\n",
    "                        flag = 1\n",
    "                    if k[2] == newEnd:\n",
    "                        endx = k[1]\n",
    "                if flag == 1:\n",
    "                    points.append([startx, endx])\n",
    "    points.sort(key = lambda x: x[0])\n",
    "    points = points[1:]\n",
    "    mergedPoints = []\n",
    "    mergedPoints.append(points[0])\n",
    "    for i in range(1, len(points)):\n",
    "        last = mergedPoints[len(mergedPoints) - 1]\n",
    "        if points[i][0] >= last[0] and points[i][0] <= last[1]: #merging overlapping regions\n",
    "            if points[i][1] > last[1]:\n",
    "                mergedPoints = mergedPoints[: len(mergedPoints)-1]\n",
    "                mergedPoints.append([last[0], points[i][1]])\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            mergedPoints.append(points[i])\n",
    "    newCode = code[: mergedPoints[0][0]]\n",
    "    plagCount = 0\n",
    "    for i in range(len(mergedPoints)):\n",
    "        if mergedPoints[i][1] > mergedPoints[i][0]:\n",
    "            plagCount += mergedPoints[i][1] - mergedPoints[i][0]\n",
    "            newCode = newCode + '\\x1b[6;30;42m' + code[mergedPoints[i][0] : mergedPoints[i][1]] + '\\x1b[0m'\n",
    "            if i < len(mergedPoints) - 1:\n",
    "                newCode = newCode + code[mergedPoints[i][1] : mergedPoints[i+1][0]]\n",
    "            else:\n",
    "                newCode = newCode + code[mergedPoints[i][1] :]\n",
    "    print(\"Approx ratio of plagiarized content in file 1: \", (plagCount/len(code)))\n",
    "    print(newCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn1 = input(\"Enter the path/name of program 1: \")\n",
    "fn2 = input(\"Enter the path/name of program 2: \")\n",
    "plagiarismCheck(fn1, fn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
